{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4 Notebook: NLP Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\happy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\happy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\happy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#for text pre-processing\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "#for model-building\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "# bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/tweets.csv', encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emotion_in_tweet_is_directed_at'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['tweet_text'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df['is_there_an_emotion_directed_at_a_brand_or_product'] == \"I can't tell\"].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions base pulled and edited from another text classification project\n",
    "\n",
    "#Convert to lowercase, strip and remove punctuation\n",
    "def preprocess(text):\n",
    "    text = str(text).lower() \n",
    "    text=text.strip()  \n",
    "    text=re.compile('<.*?>').sub('', text) \n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    return text\n",
    "\n",
    " \n",
    "#Removes Stopwords\n",
    "def stopword(string):\n",
    "    a= [i for i in string.split() if i not in stopwords.words('english')]\n",
    "    return ' '.join(a)\n",
    "\n",
    "\n",
    "#Lemmatization\n",
    "wl = WordNetLemmatizer()\n",
    " \n",
    "#Map NTLK position tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "#Tokenize the sentence\n",
    "def lemmatizer(string):\n",
    "    word_pos_tags = nltk.pos_tag(word_tokenize(string)) # Get position tags\n",
    "    a=[wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)] # Map the position tag and lemmatize the word/token\n",
    "    return \" \".join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>clean_tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>wesley g iphone hr tweet rise austin dead need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>jessedee know fludapp awesome ipad iphone app ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>swonderlin wait ipad also sale sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>sxsw hope year festival crashy year iphone app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>sxtxstate great stuff fri sxsw marissa mayer g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \\\n",
       "0                                   Negative emotion   \n",
       "1                                   Positive emotion   \n",
       "2                                   Positive emotion   \n",
       "3                                   Negative emotion   \n",
       "4                                   Positive emotion   \n",
       "\n",
       "                                    clean_tweet_text  \n",
       "0  wesley g iphone hr tweet rise austin dead need...  \n",
       "1  jessedee know fludapp awesome ipad iphone app ...  \n",
       "2                swonderlin wait ipad also sale sxsw  \n",
       "3  sxsw hope year festival crashy year iphone app...  \n",
       "4  sxtxstate great stuff fri sxsw marissa mayer g...  "
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final Pre-Processing function\n",
    "\n",
    "def finalpreprocess(string):\n",
    "    return lemmatizer(stopword(preprocess(string)))\n",
    "df['clean_tweet_text'] = df['tweet_text'].apply(lambda x: finalpreprocess(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-test split\n",
    "X = df[\"clean_tweet_text\"]\n",
    "y = df[\"is_there_an_emotion_directed_at_a_brand_or_product\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF Vector\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "X_train_vec = tfidf_vectorizer.fit_transform(X_train) \n",
    "X_test_vec = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEval():\n",
    "    '''Structure to save the model and more easily see its crossvalidation'''\n",
    "    \n",
    "    def __init__(self, model, model_name, X, y):\n",
    "        self.model = model\n",
    "        self.name = model_name\n",
    "        self.X_train_vec, self.X_test_vec, self.y_train, self.y_test = \\\n",
    "        train_test_split(X, y, random_state=42)\n",
    "        \n",
    "        y_predict_train = model.predict(X_train_vec)\n",
    "        y_prob_train = model.predict_proba(X_train_vec)[:,1]\n",
    "        \n",
    "        y_predict_test = model.predict(X_test_vec)\n",
    "        y_prob_test = model.predict_proba(X_test_vec)[:,1]\n",
    "        \n",
    "        # Attributes for cross validation\n",
    "        self.cv_results = None\n",
    "        self.cv_mean = None\n",
    "        self.cv_std = None\n",
    "        \n",
    "        \n",
    "        print('Training Report')\n",
    "        \n",
    "        print(classification_report(y_train,y_predict_train))\n",
    "        \n",
    "        print('Testing Report')\n",
    "        \n",
    "        print(classification_report(y_test,y_predict_test))\n",
    "        \n",
    "    def cross_validate(self, kfolds=10):\n",
    "        '''\n",
    "        Perform cross-validation and return results.\n",
    "        \n",
    "        Args: \n",
    "          X:\n",
    "            Optional; Training data to perform CV on. Otherwise use X from object\n",
    "          y:\n",
    "            Optional; Training data to perform CV on. Otherwise use y from object\n",
    "          kfolds:\n",
    "            Optional; Number of folds for CV (default is 10)  \n",
    "        '''\n",
    "        \n",
    "        cv_X = self.X_train_vec\n",
    "        cv_y = self.y_train\n",
    "        self.cv_results = cross_val_score(self.model, cv_X, cv_y, cv=kfolds)\n",
    "        self.cv_mean = np.mean(self.cv_results)\n",
    "        self.cv_std = np.std(self.cv_results)\n",
    "        \n",
    "        cv_summary = (\n",
    "        f'''CV Results for `{self.name}` model:\n",
    "            {self.cv_mean:.5f} ± {self.cv_std:.5f} accuracy\n",
    "        ''')\n",
    "        print(cv_summary)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Report\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "                  Negative emotion       0.00      0.00      0.00       381\n",
      "No emotion toward brand or product       0.60      1.00      0.75      3776\n",
      "                  Positive emotion       0.00      0.00      0.00      2098\n",
      "\n",
      "                          accuracy                           0.60      6255\n",
      "                         macro avg       0.20      0.33      0.25      6255\n",
      "                      weighted avg       0.36      0.60      0.45      6255\n",
      "\n",
      "Testing Report\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "                  Negative emotion       0.00      0.00      0.00       189\n",
      "No emotion toward brand or product       0.60      1.00      0.75      1612\n",
      "                  Positive emotion       0.00      0.00      0.00       880\n",
      "\n",
      "                          accuracy                           0.60      2681\n",
      "                         macro avg       0.20      0.33      0.25      2681\n",
      "                      weighted avg       0.36      0.60      0.45      2681\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happy\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\happy\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\happy\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\happy\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\happy\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\happy\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "dummy_eval = ModelEval(\n",
    "    model = dummy_model,\n",
    "    model_name = 'Dummy',\n",
    "    X = X_train_vec,\n",
    "    y = y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results for `Dummy` model:\n",
      "            0.60478 ± 0.00097 accuracy\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "dummy_eval.cross_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-61 {color: black;}#sk-container-id-61 pre{padding: 0;}#sk-container-id-61 div.sk-toggleable {background-color: white;}#sk-container-id-61 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-61 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-61 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-61 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-61 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-61 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-61 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-61 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-61 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-61 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-61 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-61 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-61 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-61 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-61 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-61 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-61 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-61 div.sk-item {position: relative;z-index: 1;}#sk-container-id-61 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-61 div.sk-item::before, #sk-container-id-61 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-61 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-61 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-61 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-61 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-61 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-61 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-61 div.sk-label-container {text-align: center;}#sk-container-id-61 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-61 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-61\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-61\" type=\"checkbox\" checked><label for=\"sk-estimator-id-61\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10, solver='liblinear')"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model\n",
    "        \n",
    "logreg_tf = LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
    "logreg_tf.fit(X_train_vec, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Report\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "                  Negative emotion       0.99      0.83      0.90       381\n",
      "No emotion toward brand or product       0.90      0.96      0.93      3776\n",
      "                  Positive emotion       0.92      0.84      0.88      2098\n",
      "\n",
      "                          accuracy                           0.91      6255\n",
      "                         macro avg       0.94      0.88      0.90      6255\n",
      "                      weighted avg       0.91      0.91      0.91      6255\n",
      "\n",
      "Testing Report\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "                  Negative emotion       0.62      0.24      0.35       189\n",
      "No emotion toward brand or product       0.71      0.81      0.76      1612\n",
      "                  Positive emotion       0.58      0.50      0.54       880\n",
      "\n",
      "                          accuracy                           0.67      2681\n",
      "                         macro avg       0.64      0.52      0.55      2681\n",
      "                      weighted avg       0.66      0.67      0.66      2681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_eval = ModelEval(\n",
    "    model = logreg_tf,\n",
    "    model_name = 'LogReg',\n",
    "    X = X_train_vec,\n",
    "    y = y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results for `LogReg` model:\n",
      "            0.68365 ± 0.01985 accuracy\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "logreg_eval.cross_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-62 {color: black;}#sk-container-id-62 pre{padding: 0;}#sk-container-id-62 div.sk-toggleable {background-color: white;}#sk-container-id-62 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-62 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-62 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-62 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-62 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-62 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-62 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-62 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-62 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-62 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-62 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-62 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-62 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-62 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-62 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-62 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-62 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-62 div.sk-item {position: relative;z-index: 1;}#sk-container-id-62 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-62 div.sk-item::before, #sk-container-id-62 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-62 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-62 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-62 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-62 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-62 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-62 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-62 div.sk-label-container {text-align: center;}#sk-container-id-62 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-62 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-62\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-62\" type=\"checkbox\" checked><label for=\"sk-estimator-id-62\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model\n",
    "\n",
    "naive_bay = MultinomialNB()\n",
    "\n",
    "naive_bay.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Report\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "                  Negative emotion       1.00      0.03      0.06       381\n",
      "No emotion toward brand or product       0.72      0.99      0.83      3776\n",
      "                  Positive emotion       0.91      0.46      0.61      2098\n",
      "\n",
      "                          accuracy                           0.75      6255\n",
      "                         macro avg       0.88      0.49      0.50      6255\n",
      "                      weighted avg       0.80      0.75      0.71      6255\n",
      "\n",
      "Testing Report\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "                  Negative emotion       0.50      0.01      0.01       189\n",
      "No emotion toward brand or product       0.65      0.95      0.77      1612\n",
      "                  Positive emotion       0.69      0.25      0.36       880\n",
      "\n",
      "                          accuracy                           0.65      2681\n",
      "                         macro avg       0.61      0.40      0.38      2681\n",
      "                      weighted avg       0.65      0.65      0.58      2681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NB_eval = ModelEval(\n",
    "    model = naive_bay,\n",
    "    model_name = 'NaiveBayes',\n",
    "    X = X_train_vec,\n",
    "    y = y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results for `NaiveBayes` model:\n",
      "            0.64592 ± 0.00731 accuracy\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "NB_eval.cross_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-63 {color: black;}#sk-container-id-63 pre{padding: 0;}#sk-container-id-63 div.sk-toggleable {background-color: white;}#sk-container-id-63 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-63 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-63 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-63 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-63 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-63 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-63 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-63 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-63 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-63 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-63 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-63 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-63 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-63 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-63 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-63 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-63 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-63 div.sk-item {position: relative;z-index: 1;}#sk-container-id-63 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-63 div.sk-item::before, #sk-container-id-63 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-63 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-63 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-63 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-63 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-63 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-63 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-63 div.sk-label-container {text-align: center;}#sk-container-id-63 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-63 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-63\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=20, max_features=4200, min_samples_leaf=4,\n",
       "                       min_samples_split=25, n_estimators=1000, n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-63\" type=\"checkbox\" checked><label for=\"sk-estimator-id-63\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=20, max_features=4200, min_samples_leaf=4,\n",
       "                       min_samples_split=25, n_estimators=1000, n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=20, max_features=4200, min_samples_leaf=4,\n",
       "                       min_samples_split=25, n_estimators=1000, n_jobs=-1)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model\n",
    "    \n",
    "rf = RandomForestClassifier(n_estimators = 1000, min_samples_split = 25, min_samples_leaf = 4, max_features = 4200, max_depth = 20, n_jobs = -1)\n",
    "rf.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Report\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "                  Negative emotion       0.95      0.09      0.17       381\n",
      "No emotion toward brand or product       0.75      0.97      0.84      3776\n",
      "                  Positive emotion       0.87      0.55      0.67      2098\n",
      "\n",
      "                          accuracy                           0.77      6255\n",
      "                         macro avg       0.85      0.54      0.56      6255\n",
      "                      weighted avg       0.80      0.77      0.75      6255\n",
      "\n",
      "Testing Report\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "                  Negative emotion       0.56      0.05      0.09       189\n",
      "No emotion toward brand or product       0.66      0.89      0.75      1612\n",
      "                  Positive emotion       0.57      0.32      0.41       880\n",
      "\n",
      "                          accuracy                           0.64      2681\n",
      "                         macro avg       0.60      0.42      0.42      2681\n",
      "                      weighted avg       0.62      0.64      0.59      2681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_eval = ModelEval(\n",
    "    model = rf,\n",
    "    model_name = 'Random Forests',\n",
    "    X = X_train_vec,\n",
    "    y = y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results for `Random Forests` model:\n",
      "            0.65956 ± 0.01918 accuracy\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "rf_eval.cross_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogReg Changed Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-66 {color: black;}#sk-container-id-66 pre{padding: 0;}#sk-container-id-66 div.sk-toggleable {background-color: white;}#sk-container-id-66 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-66 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-66 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-66 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-66 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-66 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-66 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-66 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-66 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-66 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-66 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-66 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-66 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-66 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-66 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-66 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-66 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-66 div.sk-item {position: relative;z-index: 1;}#sk-container-id-66 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-66 div.sk-item::before, #sk-container-id-66 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-66 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-66 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-66 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-66 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-66 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-66 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-66 div.sk-label-container {text-align: center;}#sk-container-id-66 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-66 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-66\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10,\n",
       "                   class_weight={&#x27;Negative emotion&#x27;: 0.75,\n",
       "                                 &#x27;No emotion toward brand or product&#x27;: 0.075,\n",
       "                                 &#x27;Positive emotion&#x27;: 0.175},\n",
       "                   solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-66\" type=\"checkbox\" checked><label for=\"sk-estimator-id-66\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10,\n",
       "                   class_weight={&#x27;Negative emotion&#x27;: 0.75,\n",
       "                                 &#x27;No emotion toward brand or product&#x27;: 0.075,\n",
       "                                 &#x27;Positive emotion&#x27;: 0.175},\n",
       "                   solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10,\n",
       "                   class_weight={'Negative emotion': 0.75,\n",
       "                                 'No emotion toward brand or product': 0.075,\n",
       "                                 'Positive emotion': 0.175},\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model\n",
    "        \n",
    "logreg_tf_cweights = LogisticRegression(solver = 'liblinear', class_weight={'Negative emotion':.75, 'No emotion toward brand or product':.075, 'Positive emotion':.175}, C=10, penalty = 'l2')\n",
    "logreg_tf_cweights.fit(X_train_vec, y_train) \n",
    "logreg_tf_cweights.fit(X_test_vec, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Report\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "                  Negative emotion       0.34      0.38      0.36       381\n",
      "No emotion toward brand or product       0.73      0.74      0.74      3776\n",
      "                  Positive emotion       0.56      0.53      0.54      2098\n",
      "\n",
      "                          accuracy                           0.65      6255\n",
      "                         macro avg       0.54      0.55      0.55      6255\n",
      "                      weighted avg       0.65      0.65      0.65      6255\n",
      "\n",
      "Testing Report\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "                  Negative emotion       0.79      0.97      0.87       189\n",
      "No emotion toward brand or product       0.91      0.88      0.89      1612\n",
      "                  Positive emotion       0.82      0.82      0.82       880\n",
      "\n",
      "                          accuracy                           0.87      2681\n",
      "                         macro avg       0.84      0.89      0.86      2681\n",
      "                      weighted avg       0.87      0.87      0.87      2681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_cweights_eval = ModelEval(\n",
    "    model = logreg_tf_cweights,\n",
    "    model_name = 'LogReg Change Weights',\n",
    "    X = X_train_vec,\n",
    "    y = y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results for `LogReg Change Weights` model:\n",
      "            0.66745 ± 0.01797 accuracy\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "logreg_cweights_eval.cross_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogReg CW + More Iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "para=[{'max_iter':[1,10,100,100],\n",
    "     'class_weight': {'Negative emotion':.75, 'No emotion toward brand or product':.075, 'Positive emotion':.175},\n",
    "     'C':[1, 5, 10]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GridSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-303-10f3428dab62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpara\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'GridSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(LogisticRegression, param_grid=para, cv=5, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "        \n",
    "logreg_cw_more_iter = LogisticRegression(solver = 'liblinear', class_weight={'Negative emotion':.75, 'No emotion toward brand or product':.075, 'Positive emotion':.175}, C=10, penalty = 'l2')\n",
    "logreg_cw_more_iter.fit(X_train_vec, y_train) \n",
    "logreg_cw_more_iter.fit(X_test_vec, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_cw_more_iter_eval = ModelEval(\n",
    "    model = logreg_cw_more_iter,\n",
    "    model_name = 'LogReg Change Weights + More Iterations',\n",
    "    X = X_train_vec,\n",
    "    y = y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_cw_more_iter_eval.cross_validate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
